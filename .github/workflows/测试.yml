name: Blue Archive DB Bruteforce

on:
  workflow_dispatch:
    inputs:
      max_length:
        description: 'Maximum key length to test'
        required: false
        default: '8'
      charset_type:
        description: 'Character set type'
        required: false
        default: 'alphanum'
        type: choice
        options:
        - alphanum
        - simple
        - full
      iteration:
        description: 'Iteration number'
        required: false
        default: '1'

jobs:
  setup:
    runs-on: ubuntu-latest
    outputs:
      run_id: ${{ steps.setup.outputs.run_id }}
      iteration: ${{ steps.setup.outputs.iteration }}
    steps:
      - uses: actions/checkout@v4
      - name: Clone repository
        run: |
          git clone --depth 1 https://x-access-token:${{ secrets.APK_SRC_REPO }}@github.com:/beichen23333/BA-Unpack.git || true
      - name: Move contents if cloned
        if: success()
        run: |
          if [ -d "BA-Unpack" ]; then
            mv BA-Unpack/* .
            rm -rf BA-Unpack
          fi
      - name: Download ExcelDB.db
        run: |
          wget -q https://prod-clientpatch.bluearchiveyostar.com/r86_vm4arsjw95mxfrp4m01q_2/TableBundles/ExcelDB.db -O ExcelDB.db || true
      - name: Create directories
        run: |
          mkdir -p progress
      - name: Setup run info
        id: setup
        run: |
          echo "run_id=run-${{ github.run_id }}-$(date +%s)" >> $GITHUB_OUTPUT
          echo "iteration=${{ github.event.inputs.iteration }}" >> $GITHUB_OUTPUT
      - name: Upload workspace
        uses: actions/upload-artifact@v4
        with:
          name: workspace-${{ steps.setup.outputs.run_id }}
          path: |
            ExcelDB.db
            lib/
            *.py
          retention-days: 3

  bruteforce:
    needs: setup
    runs-on: ubuntu-latest
    timeout-minutes: 300  # 5å°æ—¶è¶…æ—¶
    strategy:
      matrix:
        worker: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]  # æ”¹ä¸º10ä¸ªè¿›ç¨‹
      fail-fast: false
      max-parallel: 10
    steps:
      - name: Download workspace
        uses: actions/download-artifact@v4
        with:
          name: workspace-${{ needs.setup.outputs.run_id }}
          path: ./
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install xxhash pycryptodome
      - name: Create simple bruteforce script
        run: |
          cat > bruteforce_simple.py << 'EOF'
          from lib.encryption import xor_with_key
          import os
          import sys
          import time
          import string
          import itertools
          from multiprocessing import Pool, cpu_count
          import logging

          # è®¾ç½®æ—¥å¿—
          def setup_logger(worker_id):
              logger = logging.getLogger(f'worker_{worker_id}')
              logger.setLevel(logging.INFO)
              
              if not logger.handlers:
                  # æ–‡ä»¶å¤„ç†å™¨
                  fh = logging.FileHandler(f'worker_{worker_id}.log')
                  fh.setLevel(logging.INFO)
                  
                  # æŽ§åˆ¶å°å¤„ç†å™¨
                  ch = logging.StreamHandler()
                  ch.setLevel(logging.INFO)
                  
                  formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
                  fh.setFormatter(formatter)
                  ch.setFormatter(formatter)
                  
                  logger.addHandler(fh)
                  logger.addHandler(ch)
              
              return logger

          def is_valid_db(data):
              return data.startswith(b'SQLite format 3\\x00')

          def test_single_key(key):
              try:
                  with open('ExcelDB.db', 'rb') as f:
                      header = f.read(100)
                  decrypted = xor_with_key(key, header)
                  if is_valid_db(decrypted):
                      return True, key
                  return False, None
              except Exception as e:
                  return False, None

          def test_key_batch(keys):
              """æµ‹è¯•ä¸€æ‰¹å¯†é’¥"""
              results = []
              for key in keys:
                  valid, found_key = test_single_key(key)
                  if valid:
                      return [('FOUND', key)]
                  results.append(('TESTED', key))
              return results

          def generate_keys_for_worker(worker_id, total_workers=10):
              """ä¸ºç‰¹å®šworkerç”Ÿæˆå¯†é’¥"""
              # å­—ç¬¦é›†
              charset = string.ascii_letters + string.digits
              
              # æµ‹è¯•ä¸åŒé•¿åº¦
              for length in range(1, 9):  # 1-8é•¿åº¦
                  total_keys = len(charset) ** length
                  keys_per_worker = total_keys // total_workers
                  start_idx = worker_id * keys_per_worker
                  end_idx = start_idx + keys_per_worker
                  
                  if worker_id == total_workers - 1:  # æœ€åŽä¸€ä¸ªworkerå¤„ç†å‰©ä½™éƒ¨åˆ†
                      end_idx = total_keys
                  
                  logger.info(f"Testing length {length}: keys {start_idx:,} to {end_idx:,} of {total_keys:,}")
                  
                  count = 0
                  batch = []
                  batch_size = 1000
                  
                  for key_tuple in itertools.islice(itertools.product(charset, repeat=length), start_idx, end_idx):
                      key = ''.join(key_tuple)
                      batch.append(key)
                      
                      if len(batch) >= batch_size:
                          count += len(batch)
                          
                          # æµ‹è¯•æ‰¹æ¬¡
                          with Pool(min(cpu_count(), 4)) as pool:
                              batch_results = pool.map(test_single_key, batch)
                          
                          # æ£€æŸ¥ç»“æžœ
                          for valid, found_key in batch_results:
                              if valid:
                                  return found_key
                          
                          batch.clear()
                          
                          if count % 10000 == 0:
                              logger.info(f"Tested {count:,} keys for length {length}")
                  
                  # æµ‹è¯•å‰©ä½™æ‰¹æ¬¡
                  if batch:
                      count += len(batch)
                      with Pool(min(cpu_count(), 4)) as pool:
                          batch_results = pool.map(test_single_key, batch)
                      
                      for valid, found_key in batch_results:
                          if valid:
                              return found_key
              
              return None

          if __name__ == "__main__":
              if len(sys.argv) > 1:
                  worker_id = int(sys.argv[1])
              else:
                  worker_id = 0
              
              logger = setup_logger(worker_id)
              logger.info(f"ðŸš€ Starting worker {worker_id}")
              
              start_time = time.time()
              
              try:
                  result = generate_keys_for_worker(worker_id)
                  
                  if result:
                      logger.info(f"ðŸŽ¯ KEY FOUND: {result}")
                      print(f"\\033[93mðŸš¨ Worker {worker_id} FOUND KEY: {result}\\033[0m")
                      
                      with open(f'key_{worker_id}.txt', 'w') as f:
                          f.write(result)
                  else:
                      elapsed = time.time() - start_time
                      logger.info(f"âŒ No key found after {elapsed:.1f}s")
                      
              except Exception as e:
                  logger.error(f"ðŸ’¥ Worker {worker_id} failed: {e}")
                  # ä¿å­˜é”™è¯¯çŠ¶æ€
                  with open(f'worker_{worker_id}_error.txt', 'w') as f:
                      f.write(str(e))
          EOF
      - name: Run bruteforce
        run: |
          # è®¾ç½®5å°æ—¶è¶…æ—¶ï¼ˆ295åˆ†é’Ÿï¼‰
          timeout 295m python bruteforce_simple.py ${{ matrix.worker }} || exit_code=$?
          
          if [ $? -eq 124 ]; then
            echo "Worker ${{ matrix.worker }} timed out after 5 hours"
            # ä¿å­˜è¶…æ—¶çŠ¶æ€
            touch progress/timeout_${{ matrix.worker }}.txt
            echo "$(date)" > progress/timeout_${{ matrix.worker }}.txt
          fi
        continue-on-error: true
      - name: Upload results
        uses: actions/upload-artifact@v4
        with:
          name: results-worker-${{ matrix.worker }}-${{ needs.setup.outputs.run_id }}
          path: |
            key_${{ matrix.worker }}.txt
            worker_${{ matrix.worker }}.log
            worker_${{ matrix.worker }}_error.txt
            progress/timeout_${{ matrix.worker }}.txt
          retention-days: 3
        if: always()

  results:
    needs: [setup, bruteforce]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Download all results
        uses: actions/download-artifact@v4
        with:
          path: results
          pattern: results-*-${{ needs.setup.outputs.run_id }}
          merge-multiple: true
      - name: Check for found keys
        id: check-keys
        run: |
          echo "=== Bruteforce Results ==="
          echo "Run ID: ${{ needs.setup.outputs.run_id }}"
          echo "Iteration: ${{ needs.setup.outputs.iteration }}"
          echo ""
          
          found_keys=0
          for i in {0..9}; do
            if [ -f "results/key_$i.txt" ]; then
              key=$(cat "results/key_$i.txt")
              echo "ðŸŽ‰ Worker $i: KEY FOUND - $key"
              found_keys=$((found_keys + 1))
            fi
          done
          
          if [ $found_keys -gt 0 ]; then
            echo "::warning::ðŸ”‘ $found_keys valid key(s) found!"
            echo "found=true" >> $GITHUB_OUTPUT
          else
            echo "âŒ No keys found in this run"
            echo "found=false" >> $GITHUB_OUTPUT
          fi
          
          echo ""
          echo "=== Worker Status ==="
          timeout_count=0
          for i in {0..9}; do
            if [ -f "results/key_$i.txt" ]; then
              echo "âœ… Worker $i: FOUND KEY"
            elif [ -f "results/progress/timeout_$i.txt" ]; then
              echo "â° Worker $i: TIMEOUT"
              timeout_count=$((timeout_count + 1))
            elif [ -f "results/worker_$i.log" ]; then
              echo "âž– Worker $i: COMPLETED"
            else
              echo "â“ Worker $i: UNKNOWN"
            fi
          done
          
          echo ""
          echo "Timeout workers: $timeout_count/10"
          
          if [ $timeout_count -gt 0 ] && [ $found_keys -eq 0 ]; then
            echo "restart=true" >> $GITHUB_OUTPUT
            next_iteration=$(( ${{ needs.setup.outputs.iteration }} + 1 ))
            echo "next_iteration=$next_iteration" >> $GITHUB_OUTPUT
            echo "Some workers timed out, will restart..."
          else
            echo "restart=false" >> $GITHUB_OUTPUT
          fi
      - name: Restart workflow if needed
        if: steps.check-keys.outputs.restart == 'true'
        uses: actions/github-script@v6
        with:
          script: |
            await new Promise(resolve => setTimeout(resolve, 10000)); // ç­‰å¾…10ç§’
            
            await github.rest.actions.createWorkflowDispatch({
              owner: context.repo.owner,
              repo: context.repo.repo,
              workflow_id: context.workflow,
              ref: context.ref,
              inputs: {
                max_length: '${{ github.event.inputs.max_length }}',
                charset_type: '${{ github.event.inputs.charset_type }}',
                iteration: '${{ steps.check-keys.outputs.next_iteration }}'
              }
            });
            
            console.log(`Restarting workflow (iteration ${{ steps.check-keys.outputs.next_iteration }})`);
